<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">

<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"/>
  <meta name="generator" content="distill" />

  <style type="text/css">
  /* Hide doc at startup (prevent jankiness while JS renders/transforms) */
  body {
    visibility: hidden;
  }
  </style>

 <!--radix_placeholder_import_source-->
 <!--/radix_placeholder_import_source-->

  <!--radix_placeholder_meta_tags-->
  <title>Predicting Policy Domains and Preferences with BERT and Convolutional Neural Networks</title>

  <meta property="description" itemprop="description" content="We present a deep learning approach to classifying labeled texts and phrases in party manifestos, using the coding scheme and documents from the Manifesto Project Corpus."/>


  <!--  https://schema.org/Article -->
  <meta property="article:published" itemprop="datePublished" content="2020-10-10"/>
  <meta property="article:created" itemprop="dateCreated" content="2020-10-10"/>
  <meta name="article:author" content="Allison Koh"/>
  <meta name="article:author" content="Daniel Kai Sheng Boey"/>

  <!--  https://developers.facebook.com/docs/sharing/webmasters#markup -->
  <meta property="og:title" content="Predicting Policy Domains and Preferences with BERT and Convolutional Neural Networks"/>
  <meta property="og:type" content="article"/>
  <meta property="og:description" content="We present a deep learning approach to classifying labeled texts and phrases in party manifestos, using the coding scheme and documents from the Manifesto Project Corpus."/>
  <meta property="og:locale" content="en_US"/>

  <!--  https://dev.twitter.com/cards/types/summary -->
  <meta property="twitter:card" content="summary"/>
  <meta property="twitter:title" content="Predicting Policy Domains and Preferences with BERT and Convolutional Neural Networks"/>
  <meta property="twitter:description" content="We present a deep learning approach to classifying labeled texts and phrases in party manifestos, using the coding scheme and documents from the Manifesto Project Corpus."/>

  <!--/radix_placeholder_meta_tags-->
  
  <meta name="citation_reference" content="citation_title=Large scale text classification using semi-supervised multinomial naive bayes;citation_publication_date=2011;citation_publisher=Citeseer;citation_author=Jiang Su;citation_author=Jelber S Shirab;citation_author=Stan Matwin"/>
  <meta name="citation_reference" content="citation_title=Support vector machine active learning with applications to text classification;citation_publication_date=2001;citation_volume=2;citation_author=Simon Tong;citation_author=Daphne Koller"/>
  <meta name="citation_reference" content="citation_title=GloVe: Global vectors for word representation;citation_publication_date=2014;citation_author=Jeffrey Pennington;citation_author=Richard Socher;citation_author=Christopher D. Manning"/>
  <meta name="citation_reference" content="citation_title=Learning phrase representations using rnn encoder-decoder for statistical machine translation;citation_publication_date=2014;citation_author=Kyunghyun Cho;citation_author=Bart Van Merriënboer;citation_author=Caglar Gulcehre;citation_author=Dzmitry Bahdanau;citation_author=Fethi Bougares;citation_author=Holger Schwenk;citation_author=Yoshua Bengio"/>
  <meta name="citation_reference" content="citation_title=Empirical evaluation of gated recurrent neural networks on sequence modeling;citation_publication_date=2014;citation_author=Junyoung Chung;citation_author=Caglar Gulcehre;citation_author=KyungHyun Cho;citation_author=Yoshua Bengio"/>
  <meta name="citation_reference" content="citation_title=Preventing gradient explosions in gated recurrent units;citation_publication_date=2017;citation_author=Sekitoshi Kanai;citation_author=Yasuhiro Fujiwara;citation_author=Sotetsu Iwamura"/>
  <!--radix_placeholder_rmarkdown_metadata-->

  <script type="text/json" id="radix-rmarkdown-metadata">
  {"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["title","description","author","categories","date","bibliography","output","preview"]}},"value":[{"type":"character","attributes":{},"value":["Predicting Policy Domains and Preferences with BERT and Convolutional Neural Networks"]},{"type":"character","attributes":{},"value":["We present a deep learning approach to classifying labeled texts and phrases in party manifestos, using the coding scheme and documents from the Manifesto Project Corpus.\n"]},{"type":"list","attributes":{},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","url"]}},"value":[{"type":"character","attributes":{},"value":["Allison Koh"]},{"type":"character","attributes":{},"value":["http://allisonkoh.github.io"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name"]}},"value":[{"type":"character","attributes":{},"value":["Daniel Kai Sheng Boey"]}]}]},{"type":"character","attributes":{},"value":["Natural Language Processing with Deep Learning"]},{"type":"character","attributes":{},"value":["10-10-2020"]},{"type":"character","attributes":{},"value":["bibliography.bib"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["distill::distill_article"]}},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["self_contained"]}},"value":[{"type":"logical","attributes":{},"value":[false]}]}]},{"type":"character","attributes":{},"value":["figures/BERTfig3.png"]}]}
  </script>
  <!--/radix_placeholder_rmarkdown_metadata-->
  
  <script type="text/json" id="radix-resource-manifest">
  {"type":"character","attributes":{},"value":["bertcnn-classifying-manifestos_files/bowser-1.9.3/bowser.min.js","bertcnn-classifying-manifestos_files/distill-2.2.21/template.v2.js","bertcnn-classifying-manifestos_files/figure-html5/desc-country-1.png","bertcnn-classifying-manifestos_files/figure-html5/desc-pd-1.png","bertcnn-classifying-manifestos_files/figure-html5/desc-pd-2.png","bertcnn-classifying-manifestos_files/header-attrs-2.4/header-attrs.js","bertcnn-classifying-manifestos_files/jquery-1.11.3/jquery.min.js","bertcnn-classifying-manifestos_files/webcomponents-2.0.0/webcomponents.js","bertcnn-classifying-manifestos.tex","bibliography.bib","figures/BERTCNNMinor_acc_loss.png","figures/BERTfig3.png","figures/CNNMajor_acc_loss.png","figures/desc-country.png","figures/desc-major.png","figures/prf1-major.png","figures/tt.png"]}
  </script>
  <!--radix_placeholder_navigation_in_header-->
  <!--/radix_placeholder_navigation_in_header-->
  <!--radix_placeholder_distill-->

  <style type="text/css">

  body {
    background-color: white;
  }

  .pandoc-table {
    width: 100%;
  }

  .pandoc-table>caption {
    margin-bottom: 10px;
  }

  .pandoc-table th:not([align]) {
    text-align: left;
  }

  .pagedtable-footer {
    font-size: 15px;
  }

  .html-widget {
    margin-bottom: 2.0em;
  }

  .l-screen-inset {
    padding-right: 16px;
  }

  .l-screen .caption {
    margin-left: 10px;
  }

  .shaded {
    background: rgb(247, 247, 247);
    padding-top: 20px;
    padding-bottom: 20px;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
    border-bottom: 1px solid rgba(0, 0, 0, 0.1);
  }

  .shaded .html-widget {
    margin-bottom: 0;
    border: 1px solid rgba(0, 0, 0, 0.1);
  }

  .shaded .shaded-content {
    background: white;
  }

  .text-output {
    margin-top: 0;
    line-height: 1.5em;
  }

  .hidden {
    display: none !important;
  }

  d-article {
    padding-bottom: 30px;
  }

  d-appendix {
    padding-top: 30px;
  }

  d-article>p>img {
    width: 100%;
  }

  d-article iframe {
    border: 1px solid rgba(0, 0, 0, 0.1);
    margin-bottom: 2.0em;
    width: 100%;
  }

  figure img.external {
    background: white;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
    padding: 18px;
    box-sizing: border-box;
  }

  /* CSS for table of contents */

  .d-toc {
    color: rgba(0,0,0,0.8);
    font-size: 0.8em;
    line-height: 1em;
  }

  .d-toc-header {
    font-size: 0.6rem;
    font-weight: 400;
    color: rgba(0, 0, 0, 0.5);
    text-transform: uppercase;
    margin-top: 0;
    margin-bottom: 1.3em;
  }

  .d-toc a {
    border-bottom: none;
  }

  .d-toc ul {
    padding-left: 0;
  }

  .d-toc li>ul {
    padding-top: 0.8em;
    padding-left: 16px;
    margin-bottom: 0.6em;
  }

  .d-toc ul,
  .d-toc li {
    list-style-type: none;
  }

  .d-toc li {
    margin-bottom: 0.9em;
  }

  .d-toc-separator {
    margin-top: 20px;
    margin-bottom: 2em;
  }

  .d-article-with-toc {
    border-top: none;
    padding-top: 0;
  }



  /* Tweak code blocks (note that this CSS is repeated above in an injection
     into the d-code shadow dom) */

  d-code {
    overflow-x: auto !important;
  }

  pre.d-code code.d-code {
    padding-left: 10px;
    font-size: 12px;
    border-left: 2px solid rgba(0,0,0,0.1);
  }

  pre.text-output {

    font-size: 12px;
    color: black;
    background: none;
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
    text-align: left;
    white-space: pre;
    word-spacing: normal;
    word-break: normal;
    word-wrap: normal;
    line-height: 1.5;

    -moz-tab-size: 4;
    -o-tab-size: 4;
    tab-size: 4;

    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    hyphens: none;
  }

  @media(min-width: 768px) {

  d-code {
    overflow-x: visible !important;
  }

  pre.d-code code.d-code  {
      padding-left: 18px;
      font-size: 14px;
  }
  pre.text-output {
    font-size: 14px;
  }
  }

  /* Figure */

  .figure {
    position: relative;
    margin-bottom: 2.5em;
    margin-top: 1.5em;
  }

  .figure img {
    width: 100%;
  }

  .figure .caption {
    color: rgba(0, 0, 0, 0.6);
    font-size: 12px;
    line-height: 1.5em;
  }

  .figure img.external {
    background: white;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
    padding: 18px;
    box-sizing: border-box;
  }

  .figure .caption a {
    color: rgba(0, 0, 0, 0.6);
  }

  .figure .caption b,
  .figure .caption strong, {
    font-weight: 600;
    color: rgba(0, 0, 0, 1.0);
  }



  /* Tweak 1000px media break to show more text */

  @media(min-width: 1000px) {
    .base-grid,
    distill-header,
    d-title,
    d-abstract,
    d-article,
    d-appendix,
    distill-appendix,
    d-byline,
    d-footnote-list,
    d-citation-list,
    distill-footer {
      grid-template-columns: [screen-start] 1fr [page-start kicker-start] 80px [middle-start] 50px [text-start kicker-end] 65px 65px 65px 65px 65px 65px 65px 65px [text-end gutter-start] 65px [middle-end] 65px [page-end gutter-end] 1fr [screen-end];
      grid-column-gap: 16px;
    }

    .grid {
      grid-column-gap: 16px;
    }

    d-article {
      font-size: 1.06rem;
      line-height: 1.7em;
    }
    figure .caption, .figure .caption, figure figcaption {
      font-size: 13px;
    }
  }

  @media(min-width: 1180px) {
    .base-grid,
    distill-header,
    d-title,
    d-abstract,
    d-article,
    d-appendix,
    distill-appendix,
    d-byline,
    d-footnote-list,
    d-citation-list,
    distill-footer {
      grid-template-columns: [screen-start] 1fr [page-start kicker-start] 60px [middle-start] 60px [text-start kicker-end] 60px 60px 60px 60px 60px 60px 60px 60px [text-end gutter-start] 60px [middle-end] 60px [page-end gutter-end] 1fr [screen-end];
      grid-column-gap: 32px;
    }

    .grid {
      grid-column-gap: 32px;
    }
  }


  /* Get the citation styles for the appendix (not auto-injected on render since
     we do our own rendering of the citation appendix) */

  d-appendix .citation-appendix,
  .d-appendix .citation-appendix {
    font-size: 11px;
    line-height: 15px;
    border-left: 1px solid rgba(0, 0, 0, 0.1);
    padding-left: 18px;
    border: 1px solid rgba(0,0,0,0.1);
    background: rgba(0, 0, 0, 0.02);
    padding: 10px 18px;
    border-radius: 3px;
    color: rgba(150, 150, 150, 1);
    overflow: hidden;
    margin-top: -12px;
    white-space: pre-wrap;
    word-wrap: break-word;
  }


  /* Social footer */

  .social_footer {
    margin-top: 30px;
    margin-bottom: 0;
    color: rgba(0,0,0,0.67);
  }

  .disqus-comments {
    margin-right: 30px;
  }

  .disqus-comment-count {
    border-bottom: 1px solid rgba(0, 0, 0, 0.4);
    cursor: pointer;
  }

  #disqus_thread {
    margin-top: 30px;
  }

  .article-sharing a {
    border-bottom: none;
    margin-right: 8px;
  }

  .article-sharing a:hover {
    border-bottom: none;
  }

  .sidebar-section.subscribe {
    font-size: 12px;
    line-height: 1.6em;
  }

  .subscribe p {
    margin-bottom: 0.5em;
  }


  .article-footer .subscribe {
    font-size: 15px;
    margin-top: 45px;
  }


  .sidebar-section.custom {
    font-size: 12px;
    line-height: 1.6em;
  }

  .custom p {
    margin-bottom: 0.5em;
  }


  /* Improve display for browsers without grid (IE/Edge <= 15) */

  .downlevel {
    line-height: 1.6em;
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
    margin: 0;
  }

  .downlevel .d-title {
    padding-top: 6rem;
    padding-bottom: 1.5rem;
  }

  .downlevel .d-title h1 {
    font-size: 50px;
    font-weight: 700;
    line-height: 1.1em;
    margin: 0 0 0.5rem;
  }

  .downlevel .d-title p {
    font-weight: 300;
    font-size: 1.2rem;
    line-height: 1.55em;
    margin-top: 0;
  }

  .downlevel .d-byline {
    padding-top: 0.8em;
    padding-bottom: 0.8em;
    font-size: 0.8rem;
    line-height: 1.8em;
  }

  .downlevel .section-separator {
    border: none;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
  }

  .downlevel .d-article {
    font-size: 1.06rem;
    line-height: 1.7em;
    padding-top: 1rem;
    padding-bottom: 2rem;
  }


  .downlevel .d-appendix {
    padding-left: 0;
    padding-right: 0;
    max-width: none;
    font-size: 0.8em;
    line-height: 1.7em;
    margin-bottom: 0;
    color: rgba(0,0,0,0.5);
    padding-top: 40px;
    padding-bottom: 48px;
  }

  .downlevel .footnotes ol {
    padding-left: 13px;
  }

  .downlevel .base-grid,
  .downlevel .distill-header,
  .downlevel .d-title,
  .downlevel .d-abstract,
  .downlevel .d-article,
  .downlevel .d-appendix,
  .downlevel .distill-appendix,
  .downlevel .d-byline,
  .downlevel .d-footnote-list,
  .downlevel .d-citation-list,
  .downlevel .distill-footer,
  .downlevel .appendix-bottom,
  .downlevel .posts-container {
    padding-left: 40px;
    padding-right: 40px;
  }

  @media(min-width: 768px) {
    .downlevel .base-grid,
    .downlevel .distill-header,
    .downlevel .d-title,
    .downlevel .d-abstract,
    .downlevel .d-article,
    .downlevel .d-appendix,
    .downlevel .distill-appendix,
    .downlevel .d-byline,
    .downlevel .d-footnote-list,
    .downlevel .d-citation-list,
    .downlevel .distill-footer,
    .downlevel .appendix-bottom,
    .downlevel .posts-container {
    padding-left: 150px;
    padding-right: 150px;
    max-width: 900px;
  }
  }

  .downlevel pre code {
    display: block;
    border-left: 2px solid rgba(0, 0, 0, .1);
    padding: 0 0 0 20px;
    font-size: 14px;
  }

  .downlevel code, .downlevel pre {
    color: black;
    background: none;
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
    text-align: left;
    white-space: pre;
    word-spacing: normal;
    word-break: normal;
    word-wrap: normal;
    line-height: 1.5;

    -moz-tab-size: 4;
    -o-tab-size: 4;
    tab-size: 4;

    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    hyphens: none;
  }

  </style>

  <script type="application/javascript">

  function is_downlevel_browser() {
    if (bowser.isUnsupportedBrowser({ msie: "12", msedge: "16"},
                                   window.navigator.userAgent)) {
      return true;
    } else {
      return window.load_distill_framework === undefined;
    }
  }

  // show body when load is complete
  function on_load_complete() {

    // set body to visible
    document.body.style.visibility = 'visible';

    // force redraw for leaflet widgets
    if (window.HTMLWidgets) {
      var maps = window.HTMLWidgets.findAll(".leaflet");
      $.each(maps, function(i, el) {
        var map = this.getMap();
        map.invalidateSize();
        map.eachLayer(function(layer) {
          if (layer instanceof L.TileLayer)
            layer.redraw();
        });
      });
    }

    // trigger 'shown' so htmlwidgets resize
    $('d-article').trigger('shown');
  }

  function init_distill() {

    init_common();

    // create front matter
    var front_matter = $('<d-front-matter></d-front-matter>');
    $('#distill-front-matter').wrap(front_matter);

    // create d-title
    $('.d-title').changeElementType('d-title');

    // create d-byline
    var byline = $('<d-byline></d-byline>');
    $('.d-byline').replaceWith(byline);

    // create d-article
    var article = $('<d-article></d-article>');
    $('.d-article').wrap(article).children().unwrap();

    // move posts container into article
    $('.posts-container').appendTo($('d-article'));

    // create d-appendix
    $('.d-appendix').changeElementType('d-appendix');

    // create d-bibliography
    var bibliography = $('<d-bibliography></d-bibliography>');
    $('#distill-bibliography').wrap(bibliography);

    // flag indicating that we have appendix items
    var appendix = $('.appendix-bottom').children('h3').length > 0;

    // replace citations with <d-cite>
    $('.citation').each(function(i, val) {
      appendix = true;
      var cites = $(this).attr('data-cites').split(" ");
      var dt_cite = $('<d-cite></d-cite>');
      dt_cite.attr('key', cites.join());
      $(this).replaceWith(dt_cite);
    });
    // remove refs
    $('#refs').remove();

    // replace footnotes with <d-footnote>
    $('.footnote-ref').each(function(i, val) {
      appendix = true;
      var href = $(this).attr('href');
      var id = href.replace('#', '');
      var fn = $('#' + id);
      var fn_p = $('#' + id + '>p');
      fn_p.find('.footnote-back').remove();
      var text = fn_p.html();
      var dtfn = $('<d-footnote></d-footnote>');
      dtfn.html(text);
      $(this).replaceWith(dtfn);
    });
    // remove footnotes
    $('.footnotes').remove();

    $('h1.appendix, h2.appendix').each(function(i, val) {
      $(this).changeElementType('h3');
    });
    $('h3.appendix').each(function(i, val) {
      var id = $(this).attr('id');
      $('.d-toc a[href="#' + id + '"]').parent().remove();
      appendix = true;
      $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('d-appendix'));
    });

    // show d-appendix if we have appendix content
    $("d-appendix").css('display', appendix ? 'grid' : 'none');

    // replace code blocks with d-code
    $('pre>code').each(function(i, val) {
      var code = $(this);
      var pre = code.parent();
      var clz = "";
      var language = pre.attr('class');
      if (language) {
        // map unknown languages to "clike" (without this they just dissapear)
        if ($.inArray(language, ["bash", "clike", "css", "go", "html",
                                 "javascript", "js", "julia", "lua", "markdown",
                                 "markup", "mathml", "python", "svg", "xml"]) == -1)
          language = "clike";
        language = ' language="' + language + '"';
        var dt_code = $('<d-code block' + language + clz + '></d-code>');
        dt_code.text(code.text());
        pre.replaceWith(dt_code);
      } else {
        code.addClass('text-output').unwrap().changeElementType('pre');
      }
    });

    // localize layout chunks to just output
    $('.layout-chunk').each(function(i, val) {

      // capture layout
      var layout = $(this).attr('data-layout');

      // apply layout to markdown level block elements
      var elements = $(this).children().not('d-code, pre.text-output, script');
      elements.each(function(i, el) {
        var layout_div = $('<div class="' + layout + '"></div>');
        if (layout_div.hasClass('shaded')) {
          var shaded_content = $('<div class="shaded-content"></div>');
          $(this).wrap(shaded_content);
          $(this).parent().wrap(layout_div);
        } else {
          $(this).wrap(layout_div);
        }
      });


      // unwrap the layout-chunk div
      $(this).children().unwrap();
    });

    // load distill framework
    load_distill_framework();

    // wait for window.distillRunlevel == 4 to do post processing
    function distill_post_process() {

      if (!window.distillRunlevel || window.distillRunlevel < 4)
        return;

      // hide author/affiliations entirely if we have no authors
      var front_matter = JSON.parse($("#distill-front-matter").html());
      var have_authors = front_matter.authors && front_matter.authors.length > 0;
      if (!have_authors)
        $('d-byline').addClass('hidden');

      // table of contents
      if (have_authors) // adjust border if we are in authors
        $('.d-toc').parent().addClass('d-article-with-toc');

      // strip links that point to #
      $('.authors-affiliations').find('a[href="#"]').removeAttr('href');

      // hide elements of author/affiliations grid that have no value
      function hide_byline_column(caption) {
        $('d-byline').find('h3:contains("' + caption + '")').parent().css('visibility', 'hidden');
      }

      // affiliations
      var have_affiliations = false;
      for (var i = 0; i<front_matter.authors.length; ++i) {
        var author = front_matter.authors[i];
        if (author.affiliation !== "&nbsp;") {
          have_affiliations = true;
          break;
        }
      }
      if (!have_affiliations)
        $('d-byline').find('h3:contains("Affiliations")').css('visibility', 'hidden');

      // published date
      if (!front_matter.publishedDate)
        hide_byline_column("Published");

      // document object identifier
      var doi = $('d-byline').find('h3:contains("DOI")');
      var doi_p = doi.next().empty();
      if (!front_matter.doi) {
        // if we have a citation and valid citationText then link to that
        if ($('#citation').length > 0 && front_matter.citationText) {
          doi.html('Citation');
          $('<a href="#citation"></a>')
            .text(front_matter.citationText)
            .appendTo(doi_p);
        } else {
          hide_byline_column("DOI");
        }
      } else {
        $('<a></a>')
           .attr('href', "https://doi.org/" + front_matter.doi)
           .html(front_matter.doi)
           .appendTo(doi_p);
      }

       // change plural form of authors/affiliations
      if (front_matter.authors.length === 1) {
        var grid = $('.authors-affiliations');
        grid.children('h3:contains("Authors")').text('Author');
        grid.children('h3:contains("Affiliations")').text('Affiliation');
      }

      // inject pre code styles (can't do this with a global stylesheet b/c a shadow root is used)
      $('d-code').each(function(i, val) {
        var style = document.createElement('style');
        style.innerHTML = 'pre code { padding-left: 10px; font-size: 12px; border-left: 2px solid rgba(0,0,0,0.1); } ' +
                          '@media(min-width: 768px) { pre code { padding-left: 18px; font-size: 14px; } }';
        if (this.shadowRoot)
          this.shadowRoot.appendChild(style);
      });

      // move appendix-bottom entries to the bottom
      $('.appendix-bottom').appendTo('d-appendix').children().unwrap();
      $('.appendix-bottom').remove();

      // clear polling timer
      clearInterval(tid);

      // show body now that everything is ready
      on_load_complete();
    }

    var tid = setInterval(distill_post_process, 50);
    distill_post_process();

  }

  function init_downlevel() {

    init_common();

     // insert hr after d-title
    $('.d-title').after($('<hr class="section-separator"/>'));

    // check if we have authors
    var front_matter = JSON.parse($("#distill-front-matter").html());
    var have_authors = front_matter.authors && front_matter.authors.length > 0;

    // manage byline/border
    if (!have_authors)
      $('.d-byline').remove();
    $('.d-byline').after($('<hr class="section-separator"/>'));
    $('.d-byline a').remove();

    // remove toc
    $('.d-toc-header').remove();
    $('.d-toc').remove();
    $('.d-toc-separator').remove();

    // move appendix elements
    $('h1.appendix, h2.appendix').each(function(i, val) {
      $(this).changeElementType('h3');
    });
    $('h3.appendix').each(function(i, val) {
      $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('.d-appendix'));
    });


    // inject headers into references and footnotes
    var refs_header = $('<h3></h3>');
    refs_header.text('References');
    $('#refs').prepend(refs_header);

    var footnotes_header = $('<h3></h3');
    footnotes_header.text('Footnotes');
    $('.footnotes').children('hr').first().replaceWith(footnotes_header);

    // move appendix-bottom entries to the bottom
    $('.appendix-bottom').appendTo('.d-appendix').children().unwrap();
    $('.appendix-bottom').remove();

    // remove appendix if it's empty
    if ($('.d-appendix').children().length === 0)
      $('.d-appendix').remove();

    // prepend separator above appendix
    $('.d-appendix').before($('<hr class="section-separator" style="clear: both"/>'));

    // trim code
    $('pre>code').each(function(i, val) {
      $(this).html($.trim($(this).html()));
    });

    // move posts-container right before article
    $('.posts-container').insertBefore($('.d-article'));

    $('body').addClass('downlevel');

    on_load_complete();
  }


  function init_common() {

    // jquery plugin to change element types
    (function($) {
      $.fn.changeElementType = function(newType) {
        var attrs = {};

        $.each(this[0].attributes, function(idx, attr) {
          attrs[attr.nodeName] = attr.nodeValue;
        });

        this.replaceWith(function() {
          return $("<" + newType + "/>", attrs).append($(this).contents());
        });
      };
    })(jQuery);

    // prevent underline for linked images
    $('a > img').parent().css({'border-bottom' : 'none'});

    // mark non-body figures created by knitr chunks as 100% width
    $('.layout-chunk').each(function(i, val) {
      var figures = $(this).find('img, .html-widget');
      if ($(this).attr('data-layout') !== "l-body") {
        figures.css('width', '100%');
      } else {
        figures.css('max-width', '100%');
        figures.filter("[width]").each(function(i, val) {
          var fig = $(this);
          fig.css('width', fig.attr('width') + 'px');
        });

      }
    });

    // auto-append index.html to post-preview links in file: protocol
    // and in rstudio ide preview
    $('.post-preview').each(function(i, val) {
      if (window.location.protocol === "file:")
        $(this).attr('href', $(this).attr('href') + "index.html");
    });

    // get rid of index.html references in header
    if (window.location.protocol !== "file:") {
      $('.distill-site-header a[href]').each(function(i,val) {
        $(this).attr('href', $(this).attr('href').replace("index.html", "./"));
      });
    }

    // add class to pandoc style tables
    $('tr.header').parent('thead').parent('table').addClass('pandoc-table');
    $('.kable-table').children('table').addClass('pandoc-table');

    // add figcaption style to table captions
    $('caption').parent('table').addClass("figcaption");

    // initialize posts list
    if (window.init_posts_list)
      window.init_posts_list();

    // implmement disqus comment link
    $('.disqus-comment-count').click(function() {
      window.headroom_prevent_pin = true;
      $('#disqus_thread').toggleClass('hidden');
      if (!$('#disqus_thread').hasClass('hidden')) {
        var offset = $(this).offset();
        $(window).resize();
        $('html, body').animate({
          scrollTop: offset.top - 35
        });
      }
    });
  }

  document.addEventListener('DOMContentLoaded', function() {
    if (is_downlevel_browser())
      init_downlevel();
    else
      window.addEventListener('WebComponentsReady', init_distill);
  });

  </script>

  <!--/radix_placeholder_distill-->
  <script src="bertcnn-classifying-manifestos_files/header-attrs-2.4/header-attrs.js"></script>
  <script src="bertcnn-classifying-manifestos_files/jquery-1.11.3/jquery.min.js"></script>
  <script src="bertcnn-classifying-manifestos_files/bowser-1.9.3/bowser.min.js"></script>
  <script src="bertcnn-classifying-manifestos_files/webcomponents-2.0.0/webcomponents.js"></script>
  <script src="bertcnn-classifying-manifestos_files/distill-2.2.21/template.v2.js"></script>
  <!--radix_placeholder_site_in_header-->
  <!--/radix_placeholder_site_in_header-->


</head>

<body>

<!--radix_placeholder_front_matter-->

<script id="distill-front-matter" type="text/json">
{"title":"Predicting Policy Domains and Preferences with BERT and Convolutional Neural Networks","description":"We present a deep learning approach to classifying labeled texts and phrases in party manifestos, using the coding scheme and documents from the Manifesto Project Corpus.","authors":[{"author":"Allison Koh","authorURL":"http://allisonkoh.github.io","affiliation":"&nbsp;","affiliationURL":"#"},{"author":"Daniel Kai Sheng Boey","authorURL":"#","affiliation":"&nbsp;","affiliationURL":"#"}],"publishedDate":"2020-10-10T00:00:00.000+02:00","citationText":"Koh & Boey, 2020"}
</script>

<!--/radix_placeholder_front_matter-->
<!--radix_placeholder_navigation_before_body-->
<!--/radix_placeholder_navigation_before_body-->
<!--radix_placeholder_site_before_body-->
<!--/radix_placeholder_site_before_body-->

<div class="d-title">
<h1>Predicting Policy Domains and Preferences with BERT and Convolutional Neural Networks</h1>
<p><p>We present a deep learning approach to classifying labeled texts and phrases in party manifestos, using the coding scheme and documents from the Manifesto Project Corpus.</p></p>
</div>

<div class="d-byline">
  Allison Koh <a href="http://allisonkoh.github.io" class="uri">http://allisonkoh.github.io</a> 
  
,   Daniel Kai Sheng Boey  
  
<br/>10-10-2020
</div>

<div class="d-article">
<h1 id="abstract"></h1>
<p>Hand-labeled political texts are often required in empirical studies on party systems, coalition building, agenda setting, and many other areas in political science research. While hand-labeling remains the standard procedure for analyzing political texts, it can be slow and expensive, and subject to human error and disagreement. Recent studies in the field have leveraged supervised machine learning techniques to automate the labeling process of electoral programs, debate motions, and other relevant documents. We build on current approaches to label shorter texts and phrases in party manifestos using a pre-existing coding scheme developed by political scientists for classifying texts by policy domain and policy preference. Using labels and data compiled by the Manifesto Project, we make use of the state-of-the-art Bidirectional Encoder Representations from Transformers (BERT) in conjunction with Convolutional Neural Networks (CNN) and Gated Recurrent Units (GRU) to seek out the best model architecture for policy domain and policy preference classification. We find that our proposed BERT-CNN model outperforms other approaches for the task of classifying statements from English language party manifestos by major policy domain.</p>
<h2 id="intro">Introduction</h2>
<p>During campaigns, political actors communicate their position on a range of key issues to signal campaign promises and gain favor with constituents. Whilst identifying the political positions of political actors provides no certainty with regards to whether they act upon their policy preferences, it remains essential to understanding their intended political actions. This is why policy preferences—or positions on specific policy issues expressed in speech or text—have been extensively analyzed within the relevant political science literature <span class="citation" data-cites="abercrombie2019policy budge2001mapping lowe2011scaling volkens2013mapping">(Abercrombie et al. <a href="#ref-abercrombie2019policy" role="doc-biblioref">2019</a>; Budge et al. <a href="#ref-budge2001mapping" role="doc-biblioref">2001</a>; Lowe et al. <a href="#ref-lowe2011scaling" role="doc-biblioref">2011</a>; Volkens et al. <a href="#ref-volkens2013mapping" role="doc-biblioref">2013</a>)</span>. Methods employed to investigate the policy preferences of political actors include analysis of roll call voting, position extraction from elite studies or regular surveys, expert surveys and hand-coded analysis and computerized text analysis <span class="citation" data-cites="debus2009estimating">(Debus <a href="#ref-debus2009estimating" role="doc-biblioref">2009</a>)</span>. Studies that utilize political manifestos, electoral speeches, and debate motions often rely on the availability of machine-readable documents that are labeled by policy domain or policy preference.</p>
<p>Quantitative methods, especially in the field of natural language processing, have enabled the development of more scalable methods for predicting policy preferences. These advancements have enabled political scientists to analyze political texts and estimate their positions over time <span class="citation" data-cites="nanni2016topfish zirn2016classifying">(Nanni et al. <a href="#ref-nanni2016topfish" role="doc-biblioref">2016</a>; Zirn et al. <a href="#ref-zirn2016classifying" role="doc-biblioref">2016</a>)</span>. To better understand the political positions of political actors, many social science researchers have turned to hand-labeling political documents, such as parliamentary debate motions and party manifestos. Much of the previous work on analyzing political texts relies on hand-labeling documents <span class="citation" data-cites="abercrombie2018sentiment gilardi2009learning krause2011policy simmons2004globalization">(Abercrombie and Batista-Navarro <a href="#ref-abercrombie2018sentiment" role="doc-biblioref">2018</a>; Gilardi, Füglister, and Luyet <a href="#ref-gilardi2009learning" role="doc-biblioref">2009</a>; Krause <a href="#ref-krause2011policy" role="doc-biblioref">2011</a>; Simmons and Elkins <a href="#ref-simmons2004globalization" role="doc-biblioref">2004</a>)</span>. Yet, the analysis of political documents in this field stands to benefit from automating the coding of texts using supervised machine learning. Most recently, neural networks and deep language representation models have been employed in state-of-the-art approaches to automatic labeling of political texts by policy preference.</p>
<p>In this article, we present a deep learning approach to classifying labeled texts and phrases in party manifestos, using the coding scheme and documents from Manifesto Project <span class="citation" data-cites="volkens2019manifesto">(Volkens et al. <a href="#ref-volkens2019manifesto" role="doc-biblioref">2019</a>)</span>. We use English-language texts from the Manifesto Project Corpus, which divides party manifestos into statements—or <em>quasi-sentences</em>—that do not span more than one grammatical sentence. Based on the state-of-the-art deep learning methods for text classification, we propose using Bidirectional Encoder Representations from Transformers (BERT) combined with neural networks to automate the task of labeling political texts. We compare our models that combine BERT and neural networks against previous experiments with similar architectures to establish that our proposed method outperforms other approaches commonly used in natural language processing research when it comes to choosing the correct policy domain and policy preference. We identify differences in performance across policy domains, paving the way for future work on improving deep learning models for classifying political texts. To the best of our knowledge, we offer the most comprehensive application of deep language representation models incorporated with neural networks for document classification of political manifesto statements.</p>
<h2 id="related_work">Related Work</h2>
<p>Several studies have concentrated on building scaling models that identify the political position of texts <span class="citation" data-cites="glavavs2017cross laver2003extracting nanni2019political proksch2010position">(Glavaš, Nanni, and Ponzetto <a href="#ref-glavavs2017cross" role="doc-biblioref">2017</a>; Laver, Benoit, and Garry <a href="#ref-laver2003extracting" role="doc-biblioref">2003</a>; Nanni et al. <a href="#ref-nanni2019political" role="doc-biblioref">2019</a>; Proksch and Slapin <a href="#ref-proksch2010position" role="doc-biblioref">2010</a>)</span>. Previously, most of the seminal work in this area has overlooked the task of classifying texts by topic or policy area prior to detecting policy preferences associated with the topic. Over the past couple of years, several studies have addressed the gap in <em>opinion-topic identification</em> by classifying text data from political speeches, manifestos, and other documents by topic before predicting policy preference. Perhaps most relevant to our research is the paper by , in which the authors trained and validated an approach to classifying manifestos from the United States into seven policy domains that involved binary classifiers predicting whether sentences that are adjacent to one another belong to the same topic<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>. Their proposed approach of optimizing predictions using a Markov Logic framework yielded an average micro-F1 score of .749. introduced a multi-lingual classifier for automatically labeling texts by policy domain. For classification of 20,196 English-language manifestos by policy domain, their CNN models yielded an average micro-F1 score of .59.</p>
<p>More recently, studies have employed neural networks and deep language representation models to address the computationally intensive task of classifying political texts into over thirty categories. To take on this ambitious task, included contextual information about individual quasi-sentences, specifically political party and the previous sentence within a manifesto, into multi-scale convolutional neural networks with word embeddings. Their best performing model for classifying 86,500 quasi-sentences from the Manifesto Project Corpus into the seven major policy domains yielded an F1 score of .6532, and their best performing model for classifying quasi-sentences by policy preference yielded an F1 score of .4273. propose employing a hierarchical sequential deep model that captures information from within manifestos as well as contextual information across manifestos to predict the political position of texts. Their best performing hierarchical modeling approach for classifying 86,603 English language quasi-sentences yielded an F1 score of .50.</p>
<p>Abercrombie et al. (2019) <span class="citation" data-cites="abercrombie2019policy">(Abercrombie et al. <a href="#ref-abercrombie2019policy" role="doc-biblioref">2019</a>)</span> used deep language representation models to detect the policy positions of Members of Parliament in the United Kingdom. Using motions and manifestos as data sources, the authors employed a variety of methods to predict the policy and domain labels of texts. They propose utilizing BERT for this task, with results fine-tuned with party manifestos and the motions themselves. In addition to a final softmax layer, the authors added a CNN model and max-pooling layers to the soft-max layer. they found that the use of BERT demonstrated state-of-the-art performance on both manifestos and motions via supervised pipelines with a Macro-F1 score of 0.69 for their best performing model. Our work builds on some of the methods proposed in their paper, leveraging neural networks and deep language representation models for classifying political texts.</p>
<h2 id="data">The Manifesto Project Corpus</h2>
<p>The Manifesto Project Corpus<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> provides information on policy preferences of political parties from seven different countries based on a coding scheme of 8 policy domains, under which 58 policy preference codes are manually coded<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>. The Manifesto Project offers data that divides party manifestos into quasi-sentences, or individual statements which do not span more than one grammatical sentence. Quasi-sentences are then individually assigned to categories pertaining to policy domain and preference. The 58 policy preference codes, one of which is “not categorized”, refer to the position—positive or negative—of a party regarding a particular policy area. The 58 policy preference codes fall into a macro-level coding scheme comprising of 8 policy domain categories. In political science research, the Manifesto Project Corpus is particularly useful for studying party competition, the responsiveness of political parties to constituent preferences, and estimating the ideological position of political elites. While the official classification of manifestos in this dataset has primarily relied on human coders, the investigation of automatically detecting policy positions of the text data is valuable for scaling up the classification of large volumes of political texts available for analysis.</p>
<aside>
<p>Each of domain comprises of minor categories, also known as <a href="https://manifesto-project.wzb.eu/down/data/2020a/codebooks/codebook_MPDataset_MPDS2020a.pdf">policy preferences</a>. For instance, the policy preferences listed under the “External Relations” domain include:</p>
<ul>
<li>Foreign Special Relationships</li>
<li>Anti-Imperialism</li>
<li>Military</li>
<li>Peace</li>
<li>Internationalism</li>
<li>European Community/Union</li>
</ul>
</aside>
<p>Our final subset of all English-language manifestos comprises of 99,681 quasi-sentences. Figures <a href="#fig:desc-pd">1</a> and <a href="#fig:desc-country">2</a> illustrate the distribution of English-language manifestos across countries and policy domains. To ensure that the ratio between policy domains remains consistent across policy domains in running our models, we applied a 70/15/15 split between training, validation, and test sets separately for all policy domains (major categories) and policy preferences (minor categories).</p>
<div class="layout-chunk" data-layout="l-body">
<div class="figure"><span id="fig:desc-pd"></span>
<img src="bertcnn-classifying-manifestos_files/figure-html5/desc-pd-1.png" alt="Quasi-sentences (QSs) from English language manifestos by policy domain" width="50%" />
<p class="caption">
Figure 1: Quasi-sentences (QSs) from English language manifestos by policy domain
</p>
</div>
</div>
<div class="layout-chunk" data-layout="l-body">
<div class="figure"><span id="fig:desc-country"></span>
<img src="bertcnn-classifying-manifestos_files/figure-html5/desc-country-1.png" alt="Quasi-sentences (QSs) from English language manifestos by country" width="50%" />
<p class="caption">
Figure 2: Quasi-sentences (QSs) from English language manifestos by country
</p>
</div>
</div>
<h2 id="methodology">Experimental Setup</h2>
<h3 id="bidirectional-encoder-representations-from-transformers-bert">Bidirectional Encoder Representations from Transformers (BERT)</h3>
<p>Bidirectional Encoder Representations from Transformers (BERT) have proven successful in prior attempts to classify phrases and short texts <span class="citation" data-cites="devlin2018bert">(Devlin et al. <a href="#ref-devlin2018bert" role="doc-biblioref">2018</a>)</span>. BERT’s key innovation lies in its ability to apply bidirectional training of transformers to language modeling. This state-of-the-art deep language representation model uses a “masked language model”, enabling it to overcome restrictions caused by the unidirectional constraint.</p>
<p>Our experiments use the standard pre-trained BERT transformers as the embedding layer in our model. Since BERT is trained on sequences with a maximum lengths of 512 tokens, all quasi-sentences with more than 510 words were trimmed to fit this requirement. Pre-trained embeddings were frozen and not trained for the base models. We test two variants of BERT—one incorporating a bidirectional GRU model, and another incorporating CNNs. Model specifications and training times for our neural networks and deep language representation models are shown in Table <a href="#tab:modelspec" data-reference-type="ref" data-reference="tab:modelspec">1</a> and Figure <a href="#fig:tt">3</a>.</p>
<div id="tab:modelspec">
<table style="width:100%;">
<caption>Table 1: Model specifications of neural networks and deep language representation models</caption>
<colgroup>
<col style="width: 6%" />
<col style="width: 16%" />
<col style="width: 71%" />
<col style="width: 5%" />
</colgroup>
<thead>
<tr class="header">
<th>Models</th>
<th>Text Representation</th>
<th>Layers</th>
<th>Epochs</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>CNN</td>
<td>GloVe Wikipedia w-emb</td>
<td>2 Convolutional Layers (1 per filter)<br>2 Max Pooling Layers<br>1 Dropout Layer <br>1 Linear Layer</td>
<td>100</td>
</tr>
<tr class="even">
<td>BERT-CNN</td>
<td>Base BERT (uncased)</td>
<td>2 Convolutional Layers (1 per filter)<br>2 Max Pooling Layers <br>1 Dropout Layer <br>1 Linear Layer</td>
<td>10</td>
</tr>
<tr class="odd">
<td>BERT-GRU</td>
<td>Base BERT (uncased)</td>
<td>1 Bidirectional GRU RNN Layer <br>1 Dropout Layer <br>1 Linear Layer</td>
<td>10</td>
</tr>
</tbody>
</table>
</div>
<div class="layout-chunk" data-layout="l-body">
<div class="figure"><span id="fig:tt"></span>
<img src="figures/tt.png" alt="Training time for neural networks and deep language representation models for classifying political texts by *major* and *minor* policy domain" width="50%" />
<p class="caption">
Figure 3: Training time for neural networks and deep language representation models for classifying political texts by <em>major</em> and <em>minor</em> policy domain
</p>
</div>
</div>
<h3 id="bert-with-gated-recurrent-units-gru">BERT with Gated Recurrent Units (GRU)</h3>
<p>First proposed by Cho et al. (2014) <span class="citation" data-cites="cho2014learning">(Cho et al. <a href="#ref-cho2014learning" role="doc-biblioref">2014</a>)</span>, Gated Recurrent Units—formerly referred to as the RNN Encoder-Decoder model—use update gates and reset gates to solve the vanishing gradient problems often encountered in applications of recurrent neural networks <span class="citation" data-cites="kanai2017preventing">(Kanai, Fujiwara, and Iwamura <a href="#ref-kanai2017preventing" role="doc-biblioref">2017</a>)</span>. The update gate helps the model determine the extent to which past information is carried on in the model whilst the reset gate determines the information to be removed from the model <span class="citation" data-cites="chung2014empirical">(Chung et al. <a href="#ref-chung2014empirical" role="doc-biblioref">2014</a>)</span>. Hence, it solves the aforementioned problem by not completely removing the new input, instead keeping relevant information to pass on to further subsequent computed states. In our analysis, we employ a multi-layer, bidirectional GRU model from PyTorch<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a> (Table <a href="#tab:modelspec" data-reference-type="ref" data-reference="tab:modelspec">1</a>). The results are subject to a dropout layer prior to classification via a linear layer.</p>
<h3 id="bert-with-convolutional-neural-networks-cnn">BERT with Convolutional Neural Networks (CNN)</h3>
<p>We incorporate CNNs with BERT using the same CNN architecture as our baselines (Table <a href="#tab:modelspec" data-reference-type="ref" data-reference="tab:modelspec">1</a>). The model utilizes the aforementioned BERT base, uncased tokenizer with convolutional filters of sizes 2 and 3 applied with a ReLu activation function. We use a 1D-max pooling layer, a dropout layer (<span class="math inline">\(N = 0.5\)</span>) to prevent overfitting, and a Cross Entropy Loss function. We employ the model to classify policy domains (<span class="math inline">\(N = 8\)</span>) and policy preferences (<span class="math inline">\(N = 58\)</span>), each of which includes a category for quasi-sentences that do not fall into this classification scheme. Hereafter, we refer to these classifications as ‘major’ and ‘minor’ categories, respectively. A graphical representation of our model is shown in Figure <a href="#fig:bertcnn-fig">4</a>.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="figure"><span id="fig:bertcnn-fig"></span>
<img src="figures/BERTfig3.png" alt="Graphical representation of the base BERT-CNN model to predict major policy domains" width="50%" />
<p class="caption">
Figure 4: Graphical representation of the base BERT-CNN model to predict major policy domains
</p>
</div>
</div>
<h3 id="evaluation">Evaluation</h3>
<p>We evaluate the performance of our proposed method against several baselines:</p>
<ul>
<li><p><strong>Multinomial Naive Bayes</strong> <span class="citation" data-cites="su2011large">(Su, Shirab, and Matwin <a href="#ref-su2011large" role="doc-biblioref">2011</a>)</span>: This algorithm, commonly used in text classification, operates on the <em>Bag of Words assumption</em> and the assumption of <em>Conditional independence</em>.</p></li>
<li><p><strong>Support Vector Machines</strong> <span class="citation" data-cites="tong2001support">(Tong and Koller <a href="#ref-tong2001support" role="doc-biblioref">2001</a>)</span>: We used this traditional binary classifier to calculate baselines with the <code>SVC</code> package from <code>scikit-learn</code><a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a>, employing a “one-against-one” approach for multi-class classification.</p></li>
<li><p><strong>Convolutional Neural Networks (CNN)</strong> <span class="citation" data-cites="DBLP:journals/corr/Kim14f lecun1998gradient">(Kim <a href="#ref-DBLP:journals/corr/Kim14f" role="doc-biblioref">2014</a>; LeCun et al. <a href="#ref-lecun1998gradient" role="doc-biblioref">1998</a>)</span>: To run this deep learning model, originally designed for image classification, we first made use of pre-trained word vectors trained by GloVe, an unsupervised learning algorithm for obtaining vector representations for words <span class="citation" data-cites="Pennington_Socher_Manning_2014">(Pennington, Socher, and Manning <a href="#ref-Pennington_Socher_Manning_2014" role="doc-biblioref">2014</a>)</span>.</p></li>
</ul>
<p>To evaluate model fit, we utilized <em>accuracy</em> and <em>loss</em> as key metrics to compare performance of our <em>CNN</em> baseline and our proposed models (BERT-CNN, BERT-GRU). We calculated the <em>F1-score</em> for each model that we ran. In our results, we present both the Macro-F1 score and Micro-F1 score<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a>.</p>
<h3 id="architecture-fine-tuning">Architecture fine tuning</h3>
<p>We tested different modifications of the CNN and BERT models. For the CNN models, we compared the following modifications:</p>
<ul>
<li><p><strong>Stemming and Lemmatization</strong>: We test whether stemming or lemmatizing text in the pre-processing steps improves predictions using quasi-sentences from the Manifesto Project Corpus.</p></li>
<li><p><strong>Dropout rates</strong>: We decreased the dropout rate from 0.5 to 0.25 to determine whether fine-tuning dropout rates yield differences in performance. This is because we initially found that our models were overfitting.</p></li>
<li><p><strong>Additional linear layer</strong>: An additional linear layer was added prior to the final categorization linear layer to establish whether “deeper” neural networks generate improved predictions.</p></li>
<li><p><strong>Removal of uncategorized quasi-sentences</strong>: We removed quasi-sentences that were labeled as “not categorized” to investigate whether predictions improve with an altered classification scheme of 7 specified policy domains and 57 policy preference codes<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a>.</p></li>
</ul>
<p>For the BERT models, we compared the following modifications:</p>
<ul>
<li><p><strong>Training Embeddings</strong>: For our base BERT models, all training of embeddings were frozen. Therefore, we enable training of the embeddings in this modification to establish how training embeddings contributes to the performance of deep language representation models with this classification task.</p></li>
<li><p><strong>Training models based on recurrent runs</strong>: We trialed training the BERT models sequentially with different learning rates (LR = 0.001, 0.0005 and 0.0001) of 10 epochs each for a total of 30 epochs in aims to improve the performance of our neural networks and deep language representation models.</p></li>
<li><p><strong>Large, cased tokenizer</strong>: The BERT Large cased tokenizer was used instead of the BERT BASE uncased tokenizer employed in our base models.</p></li>
</ul>
<h3 id="results">Results</h3>
<p>As shown in Table <a href="#tab:modelresults">2</a>, the BERT-CNN model performed best for predicting both major and minor categories compared to the BERT-GRU model and CNN baseline. However, our SVM baseline outperformed the neural network models for predicting minor categories. We believe that the shortcomings of our neural networks and deep language representation models for this text classification task are due to limitations in specifying the number of epochs in training. We also observed overfitting in our models. For instance, with our CNN model, validation loss increased with each additional epoch after a certain number of epochs. As shown in Figure <a href="#fig:major-overfitting">5</a>, training accuracy of this model also increased at the cost of validation accuracy. However, this was not the case for deep language representation models classifying texts by minor categories. Overall, our results demonstrate that, between the two BERT models, the BERT-CNN model demonstrates superior performance against bag-of-words approaches and other models that utilize neural networks.</p>
<div id="tab:modelresults">
<table>
<caption>Table 2: Baseline, CNN and BERT models run with base model specifications as detailed in Table <a href="#tab:modelspec">1</a></caption>
<thead>
<tr class="header">
<th>Category</th>
<th>Model</th>
<th>Test Loss</th>
<th>Test Accuracy</th>
<th>Micro-F1</th>
<th>Macro-F1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><em>Major</em></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td>MNB</td>
<td>—</td>
<td>0.553</td>
<td>0.553</td>
<td>0.398</td>
</tr>
<tr class="odd">
<td></td>
<td>SVM</td>
<td>—</td>
<td>0.578</td>
<td>0.578</td>
<td>0.460</td>
</tr>
<tr class="even">
<td></td>
<td>CNN</td>
<td>1.177</td>
<td>0.589</td>
<td>0.589</td>
<td>0.466</td>
</tr>
<tr class="odd">
<td></td>
<td>BERT-GRU</td>
<td>1.166</td>
<td>0.594</td>
<td>0.593</td>
<td>0.479</td>
</tr>
<tr class="even">
<td></td>
<td>BERT-CNN</td>
<td><strong>1.152</strong></td>
<td><strong>0.591</strong></td>
<td><strong>0.591</strong></td>
<td><strong>0.473</strong></td>
</tr>
<tr class="odd">
<td><em>Minor</em></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td>MNB</td>
<td>—</td>
<td>0.385</td>
<td>0.385</td>
<td>0.154</td>
</tr>
<tr class="odd">
<td></td>
<td>SVM</td>
<td>—</td>
<td><strong>0.463</strong></td>
<td><strong>0.463</strong></td>
<td><strong>0.299</strong></td>
</tr>
<tr class="even">
<td></td>
<td>CNN</td>
<td>2.136</td>
<td>0.454</td>
<td>0.454</td>
<td>0.273</td>
</tr>
<tr class="odd">
<td></td>
<td>BERT-GRU</td>
<td>2.216</td>
<td>0.432</td>
<td>0.432</td>
<td>0.239</td>
</tr>
<tr class="even">
<td></td>
<td>BERT-CNN</td>
<td><strong>2.098</strong></td>
<td>0.448</td>
<td>0.448</td>
<td>0.260</td>
</tr>
</tbody>
</table>
</div>
<div class="layout-chunk" data-layout="l-body">
<div class="figure"><span id="fig:major-overfitting"></span>
<img src="figures/CNNMajor_acc_loss.png" alt="An illustration of overfitting in our CNN model for classifying manifesto QSs by major policy domain" width="50%" />
<p class="caption">
Figure 5: An illustration of overfitting in our CNN model for classifying manifesto QSs by major policy domain
</p>
</div>
</div>
<h3 class="unnumbered" id="cnn-and-bert-modifications">CNN and BERT Modifications</h3>
<p>Comparing modifications to our CNN models, our results suggest that the base model outperforms most alternative model specifications. As outlined in Table <a href="tab:model-modifications">3</a>, reducing the dropout rate to 0.25 improved the model on some indicators marginally. As expected, the removal of uncategorized quasi-sentences yielded improvements in predictions, with a significantly higher Macro-F1 score compared to other model specifications. Based on these results, future work should focus on how model predictions of uncategorized quasi-sentences can be improved, given their random nature.</p>
<div id="tab:model-modifications">
<table>
<caption>Table 3: Comparing results of modifications to CNN and BERT base models for predicting policy domains</caption>
<thead>
<tr class="header">
<th>Model</th>
<th>Modification</th>
<th>Test Loss</th>
<th>Test Accuracy</th>
<th>Micro-F1</th>
<th>Macro-F1</th>
<th>Epochs</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><em>CNN</em></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td>Base model</td>
<td>1.177</td>
<td><strong>0.589</strong></td>
<td><strong>0.589</strong></td>
<td>0.466</td>
<td>100</td>
</tr>
<tr class="odd">
<td></td>
<td>Lemmatized text</td>
<td><strong>1.174</strong></td>
<td>0.585</td>
<td>0.585</td>
<td>0.46</td>
<td>100</td>
</tr>
<tr class="even">
<td></td>
<td>Stemmed text</td>
<td>1.213</td>
<td>0.577</td>
<td>0.576</td>
<td>0.448</td>
<td>100</td>
</tr>
<tr class="odd">
<td></td>
<td>Dropout = 0.25</td>
<td>1.177</td>
<td><strong>0.589</strong></td>
<td>0.588</td>
<td><strong>0.467</strong></td>
<td>100</td>
</tr>
<tr class="even">
<td></td>
<td>Additional layer</td>
<td>1.18</td>
<td>0.586</td>
<td>0.586</td>
<td>0.462</td>
<td>100</td>
</tr>
<tr class="odd">
<td></td>
<td>Removing uncategorized QSs</td>
<td><strong>1.136</strong></td>
<td><strong>0.596</strong></td>
<td><strong>0.595</strong></td>
<td><strong>0.535</strong></td>
<td>100</td>
</tr>
<tr class="even">
<td><em>BERT-GRU</em></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td>Base model</td>
<td><strong>1.152</strong></td>
<td><strong>0.594</strong></td>
<td><strong>0.593</strong></td>
<td><strong>0.479</strong></td>
<td>10</td>
</tr>
<tr class="even">
<td></td>
<td>Training emb</td>
<td>1.163</td>
<td>0.592</td>
<td>0.592</td>
<td><strong>0.479</strong></td>
<td>10</td>
</tr>
<tr class="odd">
<td></td>
<td>Recurrent runs, training</td>
<td>1.234</td>
<td>0.582</td>
<td>0.581</td>
<td>0.459</td>
<td>30</td>
</tr>
<tr class="even">
<td></td>
<td>Large, uncased</td>
<td>1.172</td>
<td>0.592</td>
<td>0.591</td>
<td>0.469</td>
<td>10</td>
</tr>
<tr class="odd">
<td><em>BERT-CNN</em></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td>Base model</td>
<td>1.166</td>
<td><strong>0.591</strong></td>
<td><strong>0.591</strong></td>
<td><strong>0.473</strong></td>
<td>10</td>
</tr>
<tr class="odd">
<td></td>
<td>Training emb</td>
<td>1.167</td>
<td>0.587</td>
<td>0.587</td>
<td>0.458</td>
<td>10</td>
</tr>
<tr class="even">
<td></td>
<td>Recurrent runs, training</td>
<td><strong>1.157</strong></td>
<td>0.589</td>
<td>0.589</td>
<td>0.468</td>
<td>30</td>
</tr>
<tr class="odd">
<td></td>
<td>Large, uncased</td>
<td>1.192</td>
<td>0.58</td>
<td>0.58</td>
<td>0.45</td>
<td>10</td>
</tr>
</tbody>
</table>
</div>
<p>While we observed some improvements with modifications to the CNN model, we find that our base BERT models performed best compared to other fine-tuned modifications to model architecture. The results of our base BERT model and alternative model specifications are shown above in Table <a href="tab:model-modifications">3</a>. Even though it is possible that our base BERT model is best for this classification model, our results could also indicate the presence of over-fitting or the lack of sufficient training available given the low number of epochs.</p>
<h2 id="discussion">Limitations and Analysis</h2>
<p>As shown in Figure <a href="#fig:major-overfitting">5</a>, we observed overfitting with our major policy domain classification models. Despite employing changes and modifications to our models, including varied dropout rates, architecture fine-tuning and different learning rates, we did not find any variants of the models employed in analysis that would yield significant improvements in performance. We posit that potential improvements on these issues could be resolved by employing transfer learning and appending our sample of English-language manifestos with other political documents, such as debate transcripts.</p>
<p>In contrast, as shown in Figure <a href="#fig:minor-overfitting">6</a>, we observed little over-fitting in our minor policy domain classification models. Our classifier could benefit from employing transfer learning and appending our sample of manifesto quasi-sentences with other political texts, especially for policy domains with relatively fewer quasi-sentences to train on. It is also important to note that, compared to the more computationally intensive neural networks and deep language representation models, our Multinomial Bayes and SVM baselines did not perform significantly worse. In fact, for the minor categories, the SVM yielded superior performance in some metrics compared to that of the neural network models. Notwithstanding the lack of training of certain models, this may suggest that increasing the model complexity and consequently the computational power required may not necessarily lead to increased model performance.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="figure"><span id="fig:minor-overfitting"></span>
<img src="figures/BERTCNNMinor_acc_loss.png" alt="Training and validation metrics for the BERT-CNN model for classifying English language manifestos by policy preference" width="50%" />
<p class="caption">
Figure 6: Training and validation metrics for the BERT-CNN model for classifying English language manifestos by policy preference
</p>
</div>
</div>
<p>Substantially lower Macro-F1 scores across all models point to mixed performance in classification by category. As shown in Figure <a href="#fig:prf1-major">7</a>, we observe high variation in the performance of our classifiers between categories. However, we observe poor performance in classifying quasi-sentences that do not belong to one of the major policy domains. For our BERT-CNN model, the easiest categories to predict were “welfare and quality of life”, “economy”, and “freedom and democracy”. The superior performance of predicting the first two categories is not particularly surprising, as a substantial number of quasi-sentences in our sample of English-language party manifestos are attributed to these topics. As shown in Figure <a href="#fig:desc-pd">1</a>, 30,750 quasi-sentences are attributed to the “welfare and quality of life” category and 24,757 quasi-sentences are attributed to the “economy” domain.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="figure"><span id="fig:prf1-major"></span>
<img src="figures/prf1-major.png" alt="Average precision, recall, and Macro-F1 scores by major policy domain across all models" width="50%" />
<p class="caption">
Figure 7: Average precision, recall, and Macro-F1 scores by major policy domain across all models
</p>
</div>
</div>
<aside>
<p>The numbers on the x-axis correspond to their respective policy domains:</p>
<ul>
<li><strong>0</strong>: Not categorized</li>
<li><strong>1</strong>: External Relations</li>
<li><strong>2</strong>: Freedom and Democracy</li>
<li><strong>3</strong>: Political System</li>
<li><strong>4</strong>: Economy</li>
<li><strong>5</strong>: Welfare and Quality of Life</li>
<li><strong>6</strong>: Fabric of Society</li>
<li><strong>7</strong>: Social Groups</li>
</ul>
</aside>
<p>In contrast, the relatively superior performance of predicting the “freedom and democracy” category is surprising. Out of our total sample of <span class="math inline">\(n_{\mathrm{sentences}}=99,681\)</span>, only 4,700 documents are attributed to the “freedom and democracy” category. Intuitively, the performance of our classifier with this underrepresented policy domain could be attributed to a variety of possible explanations. One possible explanation is the presence of distinct features such as topic-unique vocabulary that do not exist in other categories. Future work on classification of political documents that fall under this category would benefit from looking into features that might distinguish this policy domain from others.</p>
<h2 id="conclusion">Conclusion</h2>
<p>In this paper, we trained two variants of BERT—one incorporating a bidirectional GRU model, and another incorporating CNNs. We demonstrate the superior performance of deep language representation models combined with neural networks to classify political domains and preferences in the Manifesto Project. Our proposed method of incorporating BERT with neural networks for classifying English language manifestos addresses issues of reproducibility and scalability in labeling large volumes of political texts. As far as we know, this is the most comprehensive application of deep language representation models and neural networks for classifying statements from political manifestos.</p>
<p>We find that using BERT in conjunction with convolutional neural networks yields the best predictions for classifying English language statements parsed from party manifestos. However, our proposed BERT-CNN model requires further fine-tuning to be effective in providing acceptable predictions to improve on less computationally intensive methods and replace human annotations of fine-grained policy positions. As expected, our proposed approach and baselines perform better for classifying major policy domains over minor categories. We also observe differences in performance between categories. Among the major policy domains, the categories that performed best include “welfare and quality of life”, “economy”, and “freedom and democracy”. The superior performance of the latter category is surprising because it makes up the smallest proportion of quasi-sentences in the Manifesto Project Corpus.</p>
<p>There are several avenues for future work on neural networks and deep language representation models for automatically labeling political texts. For instance, investigating the features of individual categories that demonstrate superior performance would shed light on how we can incorporate additional features of texts to improve model performance. This area of research would also benefit from better understanding how we can filter out texts that do not fall into a particular classification scheme. Knowledge on how these issues could be resolved to improve model performance would allow for extensions in the application of deep learning models for classifying political texts.</p>
<div id="refs" class="references hanging-indent" role="doc-bibliography">
<div id="ref-abercrombie2018sentiment">
<p>Abercrombie, Gavin, and Riza Batista-Navarro. 2018. “A Sentiment-Labelled Corpus of Hansard Parliamentary Debate Speeches.” In <em>Proceedings of the Eleventh International Conference on Language Resources and Evaluation (Lrec 2018). Ed. By Darja Fišer, Maria Eskevich, and Franciska de Jong. Miyazaki, Japan: European Language Resources Association (Elra)</em>.</p>
</div>
<div id="ref-abercrombie2019policy">
<p>Abercrombie, Gavin, Federico Nanni, Riza Theresa Batista-Navarro, and Simone Paolo Ponzetto. 2019. “Policy Preference Detection in Parliamentary Debate Motions.” In <em>Proceedings of the 23rd Conference on Computational Natural Language Learning (Conll)</em>, 249–59.</p>
</div>
<div id="ref-budge2001mapping">
<p>Budge, Ian, Hans-Dieter Klingemann, Andrea Volkens, Judith Bara, Eric Tanenbaum, and others. 2001. <em>Mapping Policy Preferences: Estimates for Parties, Electors, and Governments, 1945-1998</em>. Vol. 1. Oxford University Press on Demand.</p>
</div>
<div id="ref-cho2014learning">
<p>Cho, Kyunghyun, Bart Van Merriënboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, and Yoshua Bengio. 2014. “Learning Phrase Representations Using Rnn Encoder-Decoder for Statistical Machine Translation.” <em>arXiv Preprint arXiv:1406.1078</em>.</p>
</div>
<div id="ref-chung2014empirical">
<p>Chung, Junyoung, Caglar Gulcehre, KyungHyun Cho, and Yoshua Bengio. 2014. “Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling.” <em>arXiv Preprint arXiv:1412.3555</em>.</p>
</div>
<div id="ref-debus2009estimating">
<p>Debus, Marc. 2009. <em>Estimating the Policy Preferences of Political Actors in Germany and Europe: Methodological Advances and Empirical Applications</em>.</p>
</div>
<div id="ref-devlin2018bert">
<p>Devlin, Jacob, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. “Bert: Pre-Training of Deep Bidirectional Transformers for Language Understanding.” <em>arXiv Preprint arXiv:1810.04805</em>.</p>
</div>
<div id="ref-gilardi2009learning">
<p>Gilardi, Fabrizio, Katharina Füglister, and Stéphane Luyet. 2009. “Learning from Others: The Diffusion of Hospital Financing Reforms in Oecd Countries.” <em>Comparative Political Studies</em> 42 (4): 549–73.</p>
</div>
<div id="ref-glavavs2017cross">
<p>Glavaš, Goran, Federico Nanni, and Simone Paolo Ponzetto. 2017. “Cross-Lingual Classification of Topics in Political Texts.” In. Association for Computational Linguistics (ACL).</p>
</div>
<div id="ref-kanai2017preventing">
<p>Kanai, Sekitoshi, Yasuhiro Fujiwara, and Sotetsu Iwamura. 2017. “Preventing Gradient Explosions in Gated Recurrent Units.” In <em>Advances in Neural Information Processing Systems</em>, 435–44.</p>
</div>
<div id="ref-DBLP:journals/corr/Kim14f">
<p>Kim, Yoon. 2014. “Convolutional Neural Networks for Sentence Classification.” <em>CoRR</em> abs/1408.5882. <a href="http://arxiv.org/abs/1408.5882">http://arxiv.org/abs/1408.5882</a>.</p>
</div>
<div id="ref-krause2011policy">
<p>Krause, Rachel M. 2011. “Policy Innovation, Intergovernmental Relations, and the Adoption of Climate Protection Initiatives by Us Cities.” <em>Journal of Urban Affairs</em> 33 (1): 45–60.</p>
</div>
<div id="ref-laver2003extracting">
<p>Laver, Michael, Kenneth Benoit, and John Garry. 2003. “Extracting Policy Positions from Political Texts Using Words as Data.” <em>American Political Science Review</em> 97 (2): 311–31.</p>
</div>
<div id="ref-lecun1998gradient">
<p>LeCun, Yann, Léon Bottou, Yoshua Bengio, and Patrick Haffner. 1998. “Gradient-Based Learning Applied to Document Recognition.” <em>Proceedings of the IEEE</em> 86 (11): 2278–2324.</p>
</div>
<div id="ref-lowe2011scaling">
<p>Lowe, Will, Kenneth Benoit, Slava Mikhaylov, and Michael Laver. 2011. “Scaling Policy Preferences from Coded Political Texts.” <em>Legislative Studies Quarterly</em> 36 (1): 123–55.</p>
</div>
<div id="ref-nanni2019political">
<p>Nanni, Federico, Goran Glavas, Simone Paolo Ponzetto, and Heiner Stuckenschmidt. 2019. “Political Text Scaling Meets Computational Semantics.” <em>arXiv Preprint arXiv:1904.06217</em>.</p>
</div>
<div id="ref-nanni2016topfish">
<p>Nanni, Federico, Cäcilia Zirn, Goran Glavaš, Jason Eichorst, and Simone Paolo Ponzetto. 2016. “TopFish: Topic-Based Analysis of Political Position in Us Electoral Campaigns.”</p>
</div>
<div id="ref-Pennington_Socher_Manning_2014">
<p>Pennington, Jeffrey, Richard Socher, and Christopher D. Manning. 2014. “GloVe: Global Vectors for Word Representation.” In <em>Empirical Methods in Natural Language Processing (Emnlp)</em>, 1532–43. <a href="http://www.aclweb.org/anthology/D14-1162">http://www.aclweb.org/anthology/D14-1162</a>.</p>
</div>
<div id="ref-proksch2010position">
<p>Proksch, Sven-Oliver, and Jonathan B Slapin. 2010. “Position Taking in European Parliament Speeches.” <em>British Journal of Political Science</em> 40 (3): 587–611.</p>
</div>
<div id="ref-simmons2004globalization">
<p>Simmons, Beth A, and Zachary Elkins. 2004. “The Globalization of Liberalization: Policy Diffusion in the International Political Economy.” <em>American Political Science Review</em>, 171–89.</p>
</div>
<div id="ref-su2011large">
<p>Su, Jiang, Jelber S Shirab, and Stan Matwin. 2011. “Large Scale Text Classification Using Semi-Supervised Multinomial Naive Bayes.” In <em>Proceedings of the 28th International Conference on Machine Learning (Icml-11)</em>, 97–104. Citeseer.</p>
</div>
<div id="ref-tong2001support">
<p>Tong, Simon, and Daphne Koller. 2001. “Support Vector Machine Active Learning with Applications to Text Classification.” <em>Journal of Machine Learning Research</em> 2 (Nov): 45–66.</p>
</div>
<div id="ref-volkens2013mapping">
<p>Volkens, Andrea, Judith Bara, Ian Budge, Michael D McDonald, and Hans-Dieter Klingemann. 2013. <em>Mapping Policy Preferences from Texts: Statistical Solutions for Manifesto Analysts</em>. Vol. 3. OUP Oxford.</p>
</div>
<div id="ref-volkens2019manifesto">
<p>Volkens, Andrea, Onawa Lacewell, Pola Lehmann, Sven Regel, Henrike Schultze, and Annika Werner. 2019. “The Manifesto Data Collection. Manifesto Project (Mrg/Cmp/Marpor).” <em>Berlin: Wissenschaftszentrum Berlin Für Sozialforschung (WZB)</em>.</p>
</div>
<div id="ref-zirn2016classifying">
<p>Zirn, Cäcilia, Goran Glavaš, Federico Nanni, Jason Eichorts, and Heiner Stuckenschmidt. 2016. “Classifying Topics and Detecting Topic Shifts in Political Manifestos.”</p>
</div>
</div>
<section class="footnotes" role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p>The data used in analysis comprises of statements from six Democratic and Republican election manifestos from the 2004, 2008 and 2012 elections in the United States.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p><a href="https://manifesto-project.wzb.eu/" class="uri">https://manifesto-project.wzb.eu/</a><a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3" role="doc-endnote"><p>The classification scheme of 8 policy domains and 58 policy preferences each include a category of quasi-sentences that are not considered part of any meaningful category.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4" role="doc-endnote"><p>The classification scheme of 8 policy domains and 58 policy preferences each include a category of quasi-sentences that are not considered part of any meaningful category.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5" role="doc-endnote"><p><a href="https://pytorch.org/" class="uri">https://pytorch.org/</a><a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6" role="doc-endnote"><p>The micro score calculates metrics globally, whilst the macro score calculates metrics for each label and reports the unweighted mean.<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7" role="doc-endnote"><p>This modification is motivated by the results from our base models, which yield lower Macro-F1 scores due to the difficulty of correctly identifying the quasi-sentences that were “not categorized”.<a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
<!--radix_placeholder_article_footer-->
<!--/radix_placeholder_article_footer-->
</div>

<div class="d-appendix">
</div>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

<!--radix_placeholder_site_after_body-->
<!--/radix_placeholder_site_after_body-->
<!--radix_placeholder_appendices-->
<div class="appendix-bottom"></div>
<script id="distill-bibliography" type="text/bibtex">
@inproceedings{abercrombie2019policy,
  title={Policy preference detection in parliamentary debate motions},
  author={Abercrombie, Gavin and Nanni, Federico and Batista-Navarro, Riza Theresa and Ponzetto, Simone Paolo},
  booktitle={Proceedings of the 23rd Conference on Computational Natural Language Learning (CoNLL)},
  pages={249--259},
  year={2019}
}

@incollection{petry2009measuring,
  title={Measuring how political parties keep their promises: A positive perspective from political science},
  author={P{\'e}try, Fran{\c{c}}ois and Collette, Beno{\^\i}t},
  booktitle={Do They Walk Like They Talk?},
  pages={65--80},
  year={2009},
  publisher={Springer}
}

@inproceedings{su2011large,
  title={Large scale text classification using semi-supervised multinomial naive bayes},
  author={Su, Jiang and Shirab, Jelber S and Matwin, Stan},
  booktitle={Proceedings of the 28th international conference on machine learning (ICML-11)},
  pages={97--104},
  year={2011},
  organization={Citeseer}
}

@inproceedings{abercrombie2018sentiment,
  title={A Sentiment-labelled Corpus of Hansard Parliamentary Debate Speeches},
  author={Abercrombie, Gavin and Batista-Navarro, Riza},
  booktitle={Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018). Ed. by Darja Fi{\v{s}}er, Maria Eskevich, and Franciska de Jong. Miyazaki, Japan: European Language Resources Association (ELRA)},
  year={2018}
}

@article{berry1990state,
  title={State lottery adoptions as policy innovations: An event history analysis},
  author={Berry, Frances Stokes and Berry, William D},
  journal={The American Political Science Review},
  pages={395--415},
  year={1990},
  publisher={JSTOR}
}

@article{gilardi2009learning,
  title={Learning from others: The diffusion of hospital financing reforms in OECD countries},
  author={Gilardi, Fabrizio and F{\"u}glister, Katharina and Luyet, St{\'e}phane},
  journal={Comparative Political Studies},
  volume={42},
  number={4},
  pages={549--573},
  year={2009},
  publisher={Sage Publications Sage CA: Los Angeles, CA}
}

@article{krause2011policy,
  title={Policy innovation, intergovernmental relations, and the adoption of climate protection initiatives by US cities},
  author={Krause, Rachel M},
  journal={Journal of urban affairs},
  volume={33},
  number={1},
  pages={45--60},
  year={2011},
  publisher={Taylor \& Francis}
}

@article{simmons2004globalization,
  title={The globalization of liberalization: Policy diffusion in the international political economy},
  author={Simmons, Beth A and Elkins, Zachary},
  journal={American political science review},
  pages={171--189},
  year={2004},
  publisher={JSTOR}
}

@article{walker1969diffusion,
  title={The diffusion of innovations among the American states},
  author={Walker, Jack L},
  journal={American political science review},
  volume={63},
  number={3},
  pages={880--899},
  year={1969},
  publisher={Cambridge University Press}
}

@article{lowe2013validating,
  title={Validating estimates of latent traits from textual data using human judgment as a benchmark},
  author={Lowe, Will and Benoit, Kenneth},
  journal={Political analysis},
  volume={21},
  number={3},
  pages={298--313},
  year={2013},
  publisher={Cambridge University Press}
}

@article{eder2017manifesto,
  title={Manifesto functions: How party candidates view and use their party's central policy document},
  author={Eder, Nikolaus and Jenny, Marcelo and M{\"u}ller, Wolfgang C},
  journal={Electoral Studies},
  volume={45},
  pages={75--87},
  year={2017},
  publisher={Elsevier}
}

@article{ringquist2004lies,
  title={Lies, damned lies, and campaign promises? Environmental legislation in the 105th Congress},
  author={Ringquist, Evan J and Dasse, Carl},
  journal={Social Science Quarterly},
  volume={85},
  number={2},
  pages={400--419},
  year={2004},
  publisher={Wiley Online Library}
}

@book{budge2001mapping,
  title={Mapping policy preferences: estimates for parties, electors, and governments, 1945-1998},
  author={Budge, Ian and Klingemann, Hans-Dieter and Volkens, Andrea and Bara, Judith and Tanenbaum, Eric and others},
  volume={1},
  year={2001},
  publisher={Oxford University Press on Demand}
}

@book{volkens2013mapping,
  title={Mapping policy preferences from texts: statistical solutions for manifesto analysts},
  author={Volkens, Andrea and Bara, Judith and Budge, Ian and McDonald, Michael D and Klingemann, Hans-Dieter},
  volume={3},
  year={2013},
  publisher={OUP Oxford}
}

@book{debus2009estimating,
  title={Estimating the Policy Preferences of Political Actors in Germany and Europe: Methodological Advances and Empirical Applications},
  author={Debus, Marc},
  year={2009}
}

@article{zirn2016classifying,
  title={Classifying topics and detecting topic shifts in political manifestos},
  author={Zirn, C{\"a}cilia and Glava{\v{s}}, Goran and Nanni, Federico and Eichorts, Jason and Stuckenschmidt, Heiner},
  year={2016},
  publisher={University of Zagreb}
}

@article{nanni2016topfish,
  title={TopFish: topic-based analysis of political position in US electoral campaigns},
  author={Nanni, Federico and Zirn, C{\"a}cilia and Glava{\v{s}}, Goran and Eichorst, Jason and Ponzetto, Simone Paolo},
  year={2016},
  publisher={University of Zagreb}
}

@article{bakker2015measuring,
  title={Measuring party positions in Europe: The Chapel Hill expert survey trend file, 1999--2010},
  author={Bakker, Ryan and De Vries, Catherine and Edwards, Erica and Hooghe, Liesbet and Jolly, Seth and Marks, Gary and Polk, Jonathan and Rovny, Jan and Steenbergen, Marco and Vachudova, Milada Anna},
  journal={Party Politics},
  volume={21},
  number={1},
  pages={143--152},
  year={2015},
  publisher={SAGE Publications Sage UK: London, England}
}

@article{bakker2014anchoring,
  title={Anchoring the experts: Using vignettes to compare party ideology across countries},
  author={Bakker, Ryan and Edwards, Erica and Jolly, Seth and Polk, Jonathan and Rovny, Jan and Steenbergen, Marco},
  journal={Research \& Politics},
  volume={1},
  number={3},
  pages={2053168014553502},
  year={2014},
  publisher={SAGE Publications Sage UK: London, England}
}

@article{polk2017explaining,
  title={Explaining the salience of anti-elitism and reducing political corruption for political parties in Europe with the 2014 Chapel Hill Expert Survey data},
  author={Polk, Jonathan and Rovny, Jan and Bakker, Ryan and Edwards, Erica and Hooghe, Liesbet and Jolly, Seth and Koedam, Jelle and Kostelka, Filip and Marks, Gary and Schumacher, Gijs and others},
  journal={Research \& Politics},
  volume={4},
  number={1},
  pages={2053168016686915},
  year={2017},
  publisher={SAGE Publications Sage UK: London, England}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{volkens2019manifesto,
  title={The manifesto data collection. Manifesto project (MRG/CMP/MARPOR)},
  author={Volkens, Andrea and Lacewell, Onawa and Lehmann, Pola and Regel, Sven and Schultze, Henrike and Werner, Annika},
  journal={Berlin: Wissenschaftszentrum Berlin f{\"u}r Sozialforschung (WZB)},
  year={2019}
}

@article{lehmann2018positions,
  title={Positions and saliency of immigration in party manifestos: A novel dataset using crowd coding},
  author={Lehmann, Pola and Zobel, Malisa},
  journal={European Journal of Political Research},
  volume={57},
  number={4},
  pages={1056--1083},
  year={2018},
  publisher={Wiley Online Library}
}

@article{tong2001support,
  title={Support vector machine active learning with applications to text classification},
  author={Tong, Simon and Koller, Daphne},
  journal={Journal of machine learning research},
  volume={2},
  number={Nov},
  pages={45--66},
  year={2001}
}

@misc{devlin2018bert,
    title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
    author={Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
    year={2018},
    eprint={1810.04805},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@article{DBLP:journals/corr/Kim14f,
  author    = {Yoon Kim},
  title     = {Convolutional Neural Networks for Sentence Classification},
  journal   = {CoRR},
  volume    = {abs/1408.5882},
  year      = {2014},
  url       = {http://arxiv.org/abs/1408.5882},
  archivePrefix = {arXiv},
  eprint    = {1408.5882},
  timestamp = {Mon, 13 Aug 2018 16:46:21 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/Kim14f.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{lecun1998gradient,
  title={Gradient-based learning applied to document recognition},
  author={LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick},
  journal={Proceedings of the IEEE},
  volume={86},
  number={11},
  pages={2278--2324},
  year={1998},
  publisher={Ieee}
}

 @inproceedings{Pennington_Socher_Manning_2014, title={GloVe: Global Vectors for Word Representation}, url={http://www.aclweb.org/anthology/D14-1162}, booktitle={Empirical Methods in Natural Language Processing (EMNLP)}, author={Pennington, Jeffrey and Socher, Richard and Manning, Christopher D.}, year={2014}, pages={1532–1543} }

@article{cho2014learning,
  title={Learning phrase representations using RNN encoder-decoder for statistical machine translation},
  author={Cho, Kyunghyun and Van Merri{\"e}nboer, Bart and Gulcehre, Caglar and Bahdanau, Dzmitry and Bougares, Fethi and Schwenk, Holger and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1406.1078},
  year={2014}
}

@article{chung2014empirical,
  title={Empirical evaluation of gated recurrent neural networks on sequence modeling},
  author={Chung, Junyoung and Gulcehre, Caglar and Cho, KyungHyun and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1412.3555},
  year={2014}
}

@article{laver2003extracting,
  title={Extracting policy positions from political texts using words as data},
  author={Laver, Michael and Benoit, Kenneth and Garry, John},
  journal={American political science review},
  volume={97},
  number={2},
  pages={311--331},
  year={2003},
  publisher={Cambridge University Press}
}

@article{bilbao2018automatic,
  title={Automatic political discourse analysis with multi-scale convolutional neural networks and contextual data},
  author={Bilbao-Jayo, Aritz and Almeida, Aitor},
  journal={International Journal of Distributed Sensor Networks},
  volume={14},
  number={11},
  pages={1550147718811827},
  year={2018},
  publisher={SAGE Publications Sage UK: London, England}
}

@article{nanni2019political,
  title={Political text scaling meets computational semantics},
  author={Nanni, Federico and Glavas, Goran and Ponzetto, Simone Paolo and Stuckenschmidt, Heiner},
  journal={arXiv preprint arXiv:1904.06217},
  year={2019}
}

@article{proksch2010position,
  title={Position taking in European Parliament speeches},
  author={Proksch, Sven-Oliver and Slapin, Jonathan B},
  journal={British Journal of Political Science},
  volume={40},
  number={3},
  pages={587--611},
  year={2010},
  publisher={Cambridge University Press}
}

@inproceedings{abercrombie2018identifying,
  title={Identifying opinion-topics and polarity of parliamentary debate motions},
  author={Abercrombie, Gavin and Batista-Navarro, Riza Theresa},
  booktitle={Proceedings of the 9th workshop on computational approaches to subjectivity, sentiment and social media analysis},
  pages={280--285},
  year={2018}
}

@article{herzog2018transfer,
  title={Transfer Topic Labeling with Domain-Specific Knowledge Base: An Analysis of UK House of Commons Speeches 1935-2014},
  author={Herzog, Alexander and John, Peter and Mikhaylov, Slava Jankin},
  journal={arXiv preprint arXiv:1806.00793},
  year={2018}
}


@inproceedings{glavavs2017cross,
  title={Cross-lingual classification of topics in political texts},
  author={Glava{\v{s}}, Goran and Nanni, Federico and Ponzetto, Simone Paolo},
  year={2017},
  organization={Association for Computational Linguistics (ACL)}
}

@inproceedings{glavavs2017unsupervised,
  title={Unsupervised cross-lingual scaling of political texts},
  author={Glava{\v{s}}, Goran and Nanni, Federico and Ponzetto, Simone Paolo},
  booktitle={Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers},
  pages={688--693},
  year={2017}
}

@article{subramanian2018hierarchical,
  title={Hierarchical structured model for fine-to-coarse manifesto text analysis},
  author={Subramanian, Shivashankar and Cohn, Trevor and Baldwin, Timothy},
  journal={arXiv preprint arXiv:1805.02823},
  year={2018}
}

@article{mikolov2017advances,
  title={Advances in pre-training distributed word representations},
  author={Mikolov, Tomas and Grave, Edouard and Bojanowski, Piotr and Puhrsch, Christian and Joulin, Armand},
  journal={arXiv preprint arXiv:1712.09405},
  year={2017}
}

@misc{Volkens:2019,
Address = {Berlin},
Author = {Volkens, Andrea AND Krause, Werner AND Lehmann, Pola AND MatthieÃŸ, Theres AND Merz, Nicolas AND Regel, Sven AND WeÃŸels, Bernhard},
Publisher = {Wissenschaftszentrum Berlin fÃ¼r Sozialforschung},
Title = {The Manifesto Data Collection. Manifesto Project (MRG/CMP/MARPOR). Version 2019b},
doi = {10.25522/manifesto.mpds.2019b},
url = {https://doi.org/10.25522/manifesto.mpds.2019b},
Year = {2019}
}

@inproceedings{mikhaylov2008coder,
  title={Coder reliability and misclassification in comparative manifesto project codings},
  author={Mikhaylov, Slava and Laver, Michael and Benoit, Kenneth},
  booktitle={66th MPSA annual national conference},
  volume={3},
  number={6},
  pages={3},
  year={2008}
}

@article{lowe2011scaling,
  title={Scaling policy preferences from coded political texts},
  author={Lowe, Will and Benoit, Kenneth and Mikhaylov, Slava and Laver, Michael},
  journal={Legislative studies quarterly},
  volume={36},
  number={1},
  pages={123--155},
  year={2011},
  publisher={Wiley Online Library}
}

@book{manning2008introduction,
  title={Introduction to information retrieval},
  author={Manning, Christopher D and Raghavan, Prabhakar and Sch{\"u}tze, Hinrich},
  year={2008},
  publisher={Cambridge university press}
}

@article{xu2018random,
  title={From random to supervised: A novel dropout mechanism integrated with global information},
  author={Xu, Hengru and Li, Shen and Hu, Renfen and Li, Si and Gao, Sheng},
  journal={arXiv preprint arXiv:1808.08149},
  year={2018}
}

@inproceedings{kanai2017preventing,
  title={Preventing gradient explosions in gated recurrent units},
  author={Kanai, Sekitoshi and Fujiwara, Yasuhiro and Iwamura, Sotetsu},
  booktitle={Advances in neural information processing systems},
  pages={435--444},
  year={2017}
}
</script>
<!--/radix_placeholder_appendices-->
<!--radix_placeholder_navigation_after_body-->
<!--/radix_placeholder_navigation_after_body-->

</body>

</html>
